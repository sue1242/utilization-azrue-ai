{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特定の人物が写っているかどうか判定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Person group をトレーニング中...\n",
      "Training status: running.\n",
      "\n",
      "Training status: succeeded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType\n",
    "\n",
    "# .envファイルからキーを取得する\n",
    "load_dotenv('/.env') # 皆さんのPCでの.envファイルの保存場所に合わせて変更しましょう\n",
    "cog_key = os.getenv('COG_SERVICES_KEY')\n",
    "cog_endpoint = os.getenv('COG_SERVICES_ENDPOINT')\n",
    "\n",
    "face_client = FaceClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# ID用にランダムな文字列を生成する\n",
    "PERSON_GROUP_ID = str(uuid.uuid4())\n",
    "\n",
    "# 特定の人物を識別するためのPersonGroupを作成する\n",
    "face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name='Geoup1')\n",
    "\n",
    "# 女性、男性、子どもを登録するための変数を設定する\n",
    "# 以下のメソッドの第二引数は特定したい人物によって'Woman', 'Man', 'Child'の中から適切なものを設定する\n",
    "woman = face_client.person_group_person.create(PERSON_GROUP_ID, 'Woman')\n",
    "man = face_client.person_group_person.create(PERSON_GROUP_ID, 'Man')\n",
    "child = face_client.person_group_person.create(PERSON_GROUP_ID, 'Child')\n",
    "\n",
    "jpg_path = r'../data/5-4/person_detect/*.jpg' # 皆さんのPCの写真保管場所に合わせて変更してください\n",
    "\n",
    "# ファイル名が'w'から始まるファイルをlistに格納\n",
    "woman_images = [file for file in glob.glob(jpg_path) if file.split('/')[-1].startswith('w')]\n",
    "# ファイル名が'm'から始まるファイルをlistに格納\n",
    "man_images = [file for file in glob.glob(jpg_path) if file.split('/')[-1].startswith('m')]\n",
    "# ファイル名が'ch'から始まるファイルをlistに格納\n",
    "child_images = [file for file in glob.glob(jpg_path) if file.split('/')[-1].startswith('ch')]\n",
    "\n",
    "# 顔写真を人物に割り当てる\n",
    "for image in woman_images:\n",
    "    w = open(image, 'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, woman.person_id, w)\n",
    "\n",
    "for image in man_images:\n",
    "    m = open(image, 'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, man.person_id, m)\n",
    "\n",
    "for image in child_images:\n",
    "    ch = open(image, 'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, child.person_id, ch)\n",
    "\n",
    "# PersonGroupをトレーニングする\n",
    "print()\n",
    "print('Person group をトレーニング中...')\n",
    "face_client.person_group.train(PERSON_GROUP_ID)\n",
    "\n",
    "# 5秒毎にTraining statusを取得し、「成功」か「失敗」なら処理を終了する\n",
    "while (True):\n",
    "    training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "    print('Training status: {}.'.format(training_status.status))\n",
    "    print()\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        face_client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "        sys.exit('Person group のトレーニングが失敗しました')\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "フリーアカウントの制限回避のため、60秒待機中...\n",
      "写真test-image-person-group.jpgにPERSON GROUP ID: 0465b92a-b32d-4e24-a53f-b08c36cd8ca7の人が写っています\n"
     ]
    }
   ],
   "source": [
    "# テスト画像を取得する\n",
    "test_jpg_path = r'../data/5-4/person_detect/test-image-person-group.jpg' # 皆さんのPCの写真保管場所に合わせて変更してください\n",
    "test_image_array = glob.glob(test_jpg_path)\n",
    "image = open(test_image_array[0], 'r+b')\n",
    "\n",
    "print('フリーアカウントの制限回避のため、60秒待機中...')\n",
    "time.sleep (60)\n",
    "\n",
    "# 顔を識別する\n",
    "face_ids = []\n",
    "# 「detection model 3」を使用して識別する\n",
    "faces = face_client.face.detect_with_stream(image, detection_model='detection_03')\n",
    "for face in faces:\n",
    "    face_ids.append(face.face_id)\n",
    "\n",
    "# 識別された顔IDを変数に格納\n",
    "results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "\n",
    "if results:\n",
    "    if results[0].candidates:\n",
    "        print('写真{}にPERSON GROUP ID: {}の人が写っています'.format(os.path.basename(image.name), PERSON_GROUP_ID))\n",
    "    else:\n",
    "        print('写真{}にPERSON GROUP ID: {}の人は写っていません'.format(os.path.basename(image.name), PERSON_GROUP_ID))\n",
    "else:\n",
    "    print('写真{}に人を確認できませんでした'.format(os.path.basename(image.name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a6e928911bacb0dfa92fda4cefefc238c4c53f8ea6d7b69fadd73b22eeee23f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
