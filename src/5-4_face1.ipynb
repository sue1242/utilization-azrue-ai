{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sue1242/utilization-azrue-ai/blob/main/src/5-4_face1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なモジュールのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-cognitiveservices-vision-computervision==0.9.0 azure-cognitiveservices-vision-customvision==3.1.0 azure-cognitiveservices-vision-face==0.5.0 cognitive-face==1.5.0 python-dotenv==0.15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なデータの準備\n",
    "### 必要なファイルをGoogle Colabにアップロード\n",
    "Google Colabでの実行時のみ必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 被写体の感情を分析する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'faceAttributes': {'age': 31.0,\n",
      "                     'emotion': {'anger': 0.0,\n",
      "                                 'contempt': 0.0,\n",
      "                                 'disgust': 0.0,\n",
      "                                 'fear': 0.0,\n",
      "                                 'happiness': 1.0,\n",
      "                                 'neutral': 0.0,\n",
      "                                 'sadness': 0.0,\n",
      "                                 'surprise': 0.0},\n",
      "                     'gender': 'female'},\n",
      "  'faceId': '8646691b-867f-4c56-a69f-4ce59e22bd93',\n",
      "  'faceRectangle': {'height': 611, 'left': 273, 'top': 349, 'width': 611}}]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import cognitive_face as CF\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .envファイルからキーを取得する\n",
    "load_dotenv(r'.env') # 皆さんのPCでの.envファイルの保存場所に合わせて変更しましょう\n",
    "cog_key = os.getenv('COG_SERVICES_KEY')\n",
    "\n",
    "# Face APIのキーをcognitive_faceモジュールに認識させる\n",
    "CF.Key.set(cog_key) \n",
    "\n",
    "# API のベースとなるURLをcognitive_faceモジュールに認識させる\n",
    "BASE_URL = f'https://japaneast.api.cognitive.microsoft.com/face/v1.0'\n",
    "CF.BaseUrl.set(BASE_URL)\n",
    "\n",
    "img_path = 'utilization-azrue-ai/data/5-4/emotion_detect/fig1.jpg' # 皆さんのPCでの写真の保存場所に合わせて変更してください\n",
    "\n",
    "# cognitive_faceモジュールを活用して、Face APIを実行する\n",
    "# Face APIの詳細はリンク先をご参照ください\n",
    "# https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236\n",
    "faces = CF.face.detect(img_path, attributes='age, emotion, gender')\n",
    "\n",
    "pprint(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'../data/5-4/emotion_detect/fig1.jpg': 1.0,\n",
      " '../data/5-4/emotion_detect/fig2.jpg': 0.841,\n",
      " '../data/5-4/emotion_detect/fig3.jpg': 1.0,\n",
      " '../data/5-4/emotion_detect/fig4.jpg': 0.619,\n",
      " '../data/5-4/emotion_detect/fig5.jpg': 0.0,\n",
      " '../data/5-4/emotion_detect/fig6.jpg': 0.004}\n"
     ]
    }
   ],
   "source": [
    "# 特定のフォルダから拡張子が「.jpg」のものを抽出する\n",
    "img_path = r'utilization-azrue-ai/data/5-4/emotion_detect' # 皆さんのPCでの写真の保存場所に合わせて変更してください\n",
    "img_list = glob.glob(os.path.join(img_path, '*.jpg'))\n",
    "\n",
    "# 結果を格納する空のリストを作り、そこに結果を入れる\n",
    "happiness_values = {}\n",
    "for img in img_list:\n",
    "    faces = CF.face.detect(img, attributes='emotion, age, gender')\n",
    "    # 各人物の 'happiness' の値を一旦 tmp_list に格納する\n",
    "    tmp_list = []\n",
    "    for face in faces:\n",
    "        tmp_list.append(face['faceAttributes']['emotion']['happiness'])\n",
    "    # 画像のパスをキーとして、tmp_list の最大値を happiness_values に格納する\n",
    "    happiness_values[img] = np.max(tmp_list)\n",
    "pprint(happiness_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/5-4/emotion_detect/fig1.jpg',\n",
      " '../data/5-4/emotion_detect/fig3.jpg',\n",
      " '../data/5-4/emotion_detect/fig2.jpg']\n"
     ]
    }
   ],
   "source": [
    "# 'happiness'が0.7を超えているものだけを抽出\n",
    "happines_gt_07_imgs = [k for k, v in happiness_values.items() if v > 0.7]\n",
    "pprint(happines_gt_07_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a6e928911bacb0dfa92fda4cefefc238c4c53f8ea6d7b69fadd73b22eeee23f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
